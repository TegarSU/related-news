{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'module')))\n",
    "from openTable import *\n",
    "from filepath import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import gensim\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import Phrases\n",
    "from gensim import corpora\n",
    "\n",
    "from ast import literal_eval\n",
    "from pickle import dump\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "import pandas as pd\n",
    "from json import loads\n",
    "\n",
    "# import spacy\n",
    "from spacy.lang.id import Indonesian\n",
    "nlp = Indonesian()  # use directly\n",
    "stopwords = spacy.lang.id.stop_words.STOP_WORDS \n",
    "stopwords |= {\"nya\",\"jurusan\",\"jurus\",\"the\",\"of\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data = open_table(['entryId','content'],'BlogsEntry')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_best_topic(dictionary, corpus, texts, limit, start):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    for num_topics in range(start, limit):\n",
    "        model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=666)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        \n",
    "    #get best model\n",
    "    max_value = max(coherence_values)\n",
    "    max_index = coherence_values.index(max_value)\n",
    "    best_model = model_list[max_index]\n",
    "        \n",
    "    return best_model\n",
    "\n",
    "def make_corpus(data):\n",
    "    #Make list of list\n",
    "    mylist = []\n",
    "\n",
    "    for i,j in data.iterrows():\n",
    "        tmp = literal_eval(j.content)\n",
    "        mylist.append(tmp)\n",
    "\n",
    "    # Add bigrams and trigrams to docs,minimum count 10 means only that appear 10 times or more.\n",
    "    bigram = Phrases(mylist, min_count=10)\n",
    "    for idx in range(len(mylist)):\n",
    "        for token in bigram[mylist[idx]]:\n",
    "            if '_' in token:\n",
    "                # Token is a bigram, add to document.\n",
    "                mylist[idx].append(token)\n",
    "\n",
    "    # Create Dictionary\n",
    "    dictionary = corpora.Dictionary(mylist)\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [dictionary.doc2bow(text) for text in mylist]\n",
    "    \n",
    "    dump(corpus, open('corpus_LDA.pkl', 'wb'))\n",
    "    dictionary.save('dictionary_LDA.gensim')\n",
    "    \n",
    "    return mylist,dictionary,corpus\n",
    "    \n",
    "def save_model(model):\n",
    "    #Save Model\n",
    "    model.save('lda.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load Clean data\n",
    "# data = pd.read_csv('data_berita_clean.csv')\n",
    "\n",
    "#get data\n",
    "data = get_data()\n",
    "data = rename_column(data,{0:'entryId', 1:'content'})\n",
    "data.content = data.content.apply(preprocessing)\n",
    "\n",
    "#make corpus\n",
    "mylist,dictionary,corpus = make_corpus(data)\n",
    "\n",
    "#search optimal topic number (5)\n",
    "start=3\n",
    "limit=51\n",
    "best_model = get_best_topic(dictionary, corpus=corpus, texts=mylist, start=start, limit=limit)\n",
    "\n",
    "# x = range(start, limit)\n",
    "# plt.plot(x, coherence_values)\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Coherence score\")\n",
    "# plt.legend((\"coherence_values\"), loc='best')\n",
    "# plt.show()\n",
    "save_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.009*\"orang\" + 0.008*\"universitas\" + 0.008*\"ilmu\" + 0.007*\"kerja\" + 0.007*\"kuliah\" + 0.007*\"mahasiswa\" + 0.006*\"ajar\" + 0.005*\"milik\" + 0.005*\"sobat\" + 0.005*\"didik\"')\n",
      "(1, '0.010*\"bahasa\" + 0.008*\"ajar\" + 0.008*\"universitas\" + 0.008*\"orang\" + 0.007*\"mahasiswa\" + 0.006*\"sobat\" + 0.006*\"kuliah\" + 0.006*\"ilmu\" + 0.005*\"kerja\" + 0.005*\"teknik\"')\n",
      "(2, '0.014*\"ajar\" + 0.010*\"teknik\" + 0.008*\"orang\" + 0.008*\"kuliah\" + 0.006*\"kerja\" + 0.006*\"ilmu\" + 0.005*\"sobat\" + 0.005*\"sekolah\" + 0.005*\"universitas\" + 0.005*\"salah\"')\n",
      "(3, '0.018*\"orang\" + 0.010*\"ajar\" + 0.008*\"kerja\" + 0.008*\"kuliah\" + 0.006*\"sobat\" + 0.005*\"teknik\" + 0.005*\"mahasiswa\" + 0.005*\"milik\" + 0.005*\"ilmu\" + 0.005*\"program\"')\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "topics = best_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
